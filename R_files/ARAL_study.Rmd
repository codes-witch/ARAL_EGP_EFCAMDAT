---
title: "TODO paper title"
output:
  pdf_document: default
  html_notebook: default
---


## Preparing the environment

```{r}
setwd("/home/daniela/Documents/ARAL_EGP_EFCAMDAT/R_files/")
source("/home/daniela/Documents/ARAL_EGP_EFCAMDAT/R_files/functions.R")
library(ggplot2)
library(gridExtra)
library("dplyr")
library("stringr")
library(tidyr)
library(tools)
library(knitr)
library("tidytext")
library("tokenizers")
load("/home/daniela/Documents/ARAL_EGP_EFCAMDAT/R_files/ef2_20181231.RData")
all_features <- readLines("all_features.txt")
opts_chunk$set(cache = TRUE)
```

First, we add a column with the CEFR level that each text should belong to based on the EFCAMDAT level

```{r}
# rename the "level" column (which is at index 2)
colnames(ef2)[2] <- "ef_level"
# remove unnecessary colums
ef2 <- ef2[, !colnames(ef2) %in% c("text", "corrected", "nationality")]
# add cefr level
ef2_prepared <- add_cefr_from_ef_levels(ef2)

# mark those rows with the first and last units of a CEFR level
# This will help us group them
ef2_prepared <- add_combined_level(ef2_prepared)
```

Now, get the learnerIDs of people for whome we have all necessary units. Generally, these are the first three and last three of their respective CEFR level. 
In the case of A1, They need to have the first six units and the last three units. In the case of C2, they need only the first three units.

```{r}
# Get those students that completed each level
# (except C2, for which we only need the students who completed the first three units)


cefr_ef_lvls <- list( # These are the EFCamDat levels that correspond to each CEFR level
  "A1" = c(1:3),
  "A2" = c(4:6),
  "B1" = c(7:9),
  "B2" = c(10:12),
  "C1" = c(13:15),
  "C2" = c(16)
)

# A dataframe containing the (ef_level, unit) pairs that we are interested in
ef_lvl_unit_df <- data.frame(ef_lvl = sapply(cefr_ef_lvls, ))
ef_lvl_unit_df
list_students_finsihed <- list()


for (cur_cefr_lvl in names(cefr_ef_lvls)) {
  # Minimum number of texts that the learner should have completed within the subset that will be taken into account
  min_n_texts <- 6 # (only top 3 and highest and lowest units in the level)

  if (cur_cefr_lvl == "A1") {
    min_n_texts <- 9 # top 6 lowest + top 3 highest
  } else if (cur_cefr_lvl == "C2") {
    min_n_texts <- 3 # top 3 lowest
  }

  learners_finished <- ef2_prepared %>%
    filter(cefr_level == cur_cefr_lvl & !is.na(combined_cefr)) %>% # current cefr level top high/low units
    group_by(learnerID) %>%
    summarise(units_count = n_distinct(ef_level, unit)) %>% # number of unique ef_level-unit pairs each learner has completed
    filter(units_count == min_n_texts) %>% # only those that have completed all units at least once
    pull(learnerID)

  list_students_finsihed[[cur_cefr_lvl]] <- learners_finished
}

# Check how many students we have for each level:
for (lvl in names(list_students_finsihed)) {
  print(paste(lvl, length(list_students_finsihed[[lvl]])))
}

# 49 is the minimum number of students having finished a level (C1)
min_num_students <- min(sapply(list_students_finsihed, length))

print(min_num_students)
```

We now know that in order to have a balanced sample, we can have at most 49 students of any given level in the combined CEFR levels.
Namely, each combined class will have 49 students from the lower level and 49 students from the higher level.

From the learners who completed the levels, we must sample 49 without replacement.
These people's texts in the first and last three units of their CEFR levels will be the ones to be analyzed.
In total, at each combined level we will have scripts written by 98 students and we will use them as a "snapshot" of their proficiency once the lower level reached.

Now, we must sample the students and extract their texts to be analyzed by the POLKE tool.

```{r}
sampled_learners <- list()
set.seed(1234)
for (level in names(cefr_ef_lvls)) {
  sampled_learners[[level]] <- sample(list_students_finsihed[[level]], min_num_students, replace = FALSE)
}

# To check that the sampling is deterministic, run this line several times and check the learnerIDs
# sapply(sampled_learners, function(x) sort(unique(x)))
```

Students have been sampled. Now, we need to extract their texts and put them in .txt files to be analyzed by the python script.

```{r}
input_path <- "/home/daniela/Documents/ARAL_EGP_EFCAMDAT/text_annotation/data/input_21Nov24/"
df_filtered_all <- ef2_prepared[0, ]

# make dataframe with the learners that we want at each level
for (lvl in names(cefr_ef_lvls)) {
  filtered_df <- ef2_prepared %>%
    filter(cefr_level == lvl & learnerID %in% sampled_learners[[lvl]] & !is.na(combined_cefr))

  df_filtered_all <- rbind(df_filtered_all, filtered_df)
}

# Put the texts into .txt files
# ef_text_2_txt(df_filtered_all, input_path)
```

Now, we run the Python script and wait. It will take a while. 

Once the scripts have been annotated, we need to count how many times each student at the individual CEFR levels have used each construct.

```{r}
# For getting the output path dynamically given the level
# file_format can be txt or csv
get_output_path <- function(combined_lvl, file_format = "csv") {
  # NOTE change the output path if needed
  return(paste0("../text_annotation/data/output_21Nov24/", combined_lvl, "/", file_format, "/"))
}

get_learner_ids_by_lvl <- function(combined_lvl) {
  last_lvl <- str_split_i(combined_lvl, "_", 2) # high level in the combination
  first_lvl <- str_split_i(combined_lvl, "_", 1)
  if (last_lvl == "A1") { # If it's A0_A1, all learners are from A1
    learner_ids <- sampled_learners[["A1"]]
  } else { # get learners from the last level and the first one
    learner_ids <- sort(unique(append(sampled_learners[[first_lvl]], sampled_learners[[last_lvl]])))
  }
}

# Calls the get_feat_count_per_student with the necessary parameters given the level combination
count_constrs_by_lvl <- function(combined_lvl, make_long = TRUE) {
  learner_ids <- get_learner_ids_by_lvl(combined_lvl)

  return(get_feat_count_per_student(
    directory_path = get_output_path(combined_lvl),
    learner_ids = learner_ids,
    make_long = make_long
  ))
}

# learner_wc_by_level <-

# These dfs contain the feature counts for all learners at each combined level
a0a1_feat_counts <- count_constrs_by_lvl("A0_A1", make_long = FALSE)
a1a2_feat_counts <- count_constrs_by_lvl("A1_A2", make_long = FALSE)
a2b1_feat_counts <- count_constrs_by_lvl("A2_B1", make_long = FALSE)
b1b2_feat_counts <- count_constrs_by_lvl("B1_B2", make_long = FALSE)
b2c1_feat_counts <- count_constrs_by_lvl("B2_C1", make_long = FALSE)
c1c2_feat_counts <- count_constrs_by_lvl("C1_C2", make_long = FALSE)
```

Now it is necessary to normalize these counts by number of words written by each individual student in the respective (combined) levels and normalize it by 100 words

```{r}
a0a1_word_counts <- get_learner_word_count_df(get_learner_ids_by_lvl("A0_A1"), get_output_path("A0_A1", "text"))
a1a2_word_counts <- get_learner_word_count_df(get_learner_ids_by_lvl("A1_A2"), get_output_path("A1_A2", "text"))
a2b1_word_counts <- get_learner_word_count_df(get_learner_ids_by_lvl("A2_B1"), get_output_path("A2_B1", "text"))
b1b2_word_counts <- get_learner_word_count_df(get_learner_ids_by_lvl("B1_B2"), get_output_path("B1_B2", "text"))
b2c1_word_counts <- get_learner_word_count_df(get_learner_ids_by_lvl("B2_C1"), get_output_path("B2_C1", "text"))
c1c2_word_counts <- get_learner_word_count_df(get_learner_ids_by_lvl("C1_C2"), get_output_path("C1_C2", "text"))


a0a1_normalized <- cbind(get_feats_normalized_students(a0a1_feat_counts, a0a1_word_counts), text_level = "A0_A1")
a1a2_normalized <- cbind(get_feats_normalized_students(a1a2_feat_counts, a1a2_word_counts), text_level = "A1_A2")
a2b1_normalized <- cbind(get_feats_normalized_students(a2b1_feat_counts, a2b1_word_counts), text_level = "A2_B1")
b1b2_normalized <- cbind(get_feats_normalized_students(b1b2_feat_counts, b1b2_word_counts), text_level = "B1_B2")
b2c1_normalized <- cbind(get_feats_normalized_students(b2c1_feat_counts, b2c1_word_counts), text_level = "B2_C1")
c1c2_normalized <- cbind(get_feats_normalized_students(c1c2_feat_counts, c1c2_word_counts), text_level = "C1_C2")
```

Now we know the normalized frequency of each costruct for the students at each level combination. 


First, we get rid of all constructs which were not found in any student's writings:

```{r}
# put all dataframes together
normalized_all_levels <- rbind(a0a1_normalized, a1a2_normalized, a2b1_normalized, b1b2_normalized, b2c1_normalized, c1c2_normalized)

# if there are any NAs, it's because texts by some students could not be processed. Drop these rows
normalized_all_levels <- normalized_all_levels %>%
  drop_na()

zero_constructs <- normalized_all_levels %>%
  group_by(feature) %>%
  filter(all(total == 0)) %>%
  pull(feature) %>%
  unique()

# remove these zero-constructs from our data
normalized_all_levels <- normalized_all_levels %>%
  filter(!feature %in% zero_constructs)
```

We can start statistically analyzing the construct frequency distributions per learner. 

```{r}
# check for normality

library("ggpubr")
normalized_all_levels %>%
  pull(total) %>%
  ggdensity()
```

We observe that the data is essentialy exponential, with a vast majority of the constructs having close to zero frequecy. 
Log transforming the data does not reveal a normal distribution either.


```{r}
# Log-transform and visualize
library("ggpubr")
normalized_all_levels %>%
  pull(total) %>%
  log() %>%
  ggdensity()
```

It is therefore wise to use non-parametric tests.

First, we will apply the Kruskal-Wallis test to identify any constructs that do not vary significantly across proficiency levels.


```{r}
constructs <- unique(normalized_all_levels$feature)
kw_results <- list()  # mapping between 
kw_non_sign_constructs <- c()
kw_sign_constructs <- c()
kw_nan_results_constructs <- c()

for (constr in constructs) {
  # df with only the current construct. Check whether there are no occurrences of the feature.
  feature_dataframe <- normalized_all_levels %>%
    filter(feature == constr)

  # Fill in kw result list
  kw_results[[constr]] <- normalized_all_levels %>%
    filter(feature == constr) %>%
    kruskal.test(total ~ text_level, data = .)

  p_value <- kw_results[[constr]]$p.value

  if (is.nan(p_value)) { # sanity check: kw_nan_results_constructs will remain empty because we are discarding all features with no occurrences
    kw_nan_results_constructs <- append(kw_nan_results_constructs, constr)
  } else if (p_value > 0.05) {
    kw_non_sign_constructs <- append(kw_non_sign_constructs, constr)
  } else {
    kw_sign_constructs <- append(kw_sign_constructs, constr)
  }
}
```

A total of 155 constructs do not show significant differences across levels.
```{r}
length(kw_non_sign_constructs)

kw_non_sign_constructs <- data.frame(feature = kw_non_sign_constructs) %>%
  add_feature_level()

# Add the level that the EGP assigns to these constructs
View(kw_non_sign_constructs)
```


TODO Sample 2 from each level and try and find them?


```{r}
# For all significant construct, do Wilcoxon Rank Sum tests to check for significant differences between the current level and the previous one. 
levels <- c("A0_A1", "A1_A2", "A2_B1", "B1_B2", "B2_C1", "C1_C2")

# store p-values from wilcoxon tests for each construct
wcx_pvals <- data.frame(matrix(ncol = 6, nrow = length(kw_sign_constructs)))
names(wcx_pvals) <- c("feature", "A1", "A2", "B1", "B2", "C1")

# For all relevant constructs, do a wilcoxon-test between all consecutive levels
for (f in 1:length(kw_sign_constructs)) {
  constr <- kw_sign_constructs[f]
  # build the rows for the p-values column by column
  wcx_pvals_vec <- c()

  for (i in 1:(length(levels) - 1)){
    level1 <- levels[i]
    level2 <- levels[i + 1]
    print(paste0("Construct: ", constr))

    appears_in_lev1 <- sum(filter(normalized_all_levels, text_level == level1, feature == constr)$total) > 0
    appears_in_lev2 <- sum(filter(normalized_all_levels, text_level == level2, feature == constr)$total) > 0

    # Check that the current feature appears in the level before and in the current level
    if (!appears_in_lev1 || !appears_in_lev2) {
      if (!appears_in_lev1 && !appears_in_lev2) {
        print(paste0("Contsruct ", constr, " does not appear in any texts written by ", level1, " or ", level2, " students"))
      } else if (!appears_in_lev1) {
        print(paste0("Contsruct ", constr, " does not appear in any texts written by ", level1, " students"))
      } else if (!appears_in_lev2) {
        print(paste0("Contsruct ", constr, " does not appear in any texts written by ", level2, " students"))
      }

      wcx_pvals_vec <- append(wcx_pvals_vec, NA)

    } else { # It must appear in BOTH levels to be compared
      wcx_result <- normalized_all_levels %>%
        filter(feature == constr, text_level %in% c(level1, level2)) %>%
        wilcox.test(total ~ text_level, data = ., alternative = "less")

      if (wcx_result$p.value <= 0.05) {
        wcx_pvals_vec <- append(wcx_pvals_vec, wcx_result$p.value)
      } else {
        wcx_pvals_vec <- append(wcx_pvals_vec, NA)
      }
    }
  }

  constr_pval_row <- append(as.character(constr), wcx_pvals_vec)

  wcx_pvals[f, ] <- constr_pval_row

}
```


Based on the p-values, we predict the level of acquisition operationalized as the first level in which the per-student frequencies differ significantly between the start and end of the level.

```{r}
wcx_level_predict <-  data.frame(feature = kw_sign_constructs) %>%
  add_feature_level() %>%
  rename(EGP_level = feat_level) %>%
  rename(construct = feature) %>%
  mutate(first_sign_p_pred = NA, signif_at_EGP_level = NA)
# Find first significant diff
wcx_level_predict <- fill_first_signif_pred(wcx_pvals, wcx_level_predict)

# fill in TRUE FALSE, is there a significant difference at the level the EGP says?
wcx_level_predict <- fill_is_sig_at_lvl(wcx_pvals, wcx_level_predict)
```


```{r}
View(wcx_level_predict)
```

Now that we have some frequency-based predictions for the alignment between constructs and levels, we would like to see how they compare with the EGP alignments.

For this, we use precision, recall, and F1-scores. 

```{r}
# Calculate precision, recall and F1 for t-tests predictions

# get only the predictions for levels
#we lack enough C2 data to look at both beginning and end, so our approach will never assign C2 as an acquisition level. Therefore, we filter out EGP-C2 constructs
# Also,  there are no significant differences between consecutive combined levels for the construct, we cannot make a prediction and get an NA. Ignore those.
wcx_predictions <- wcx_level_predict %>%
  filter(EGP_level != "C2") %>%
  filter(!is.na(first_sign_p_pred)) %>%
  pull(first_sign_p_pred)

# get the EGP level assignments
egp_expected <- wcx_level_predict %>%
  filter(EGP_level != "C2" & !is.na(first_sign_p_pred)) %>%
  pull(EGP_level)


# This calculates the precision and recall for having predicted the exact level.
exact_metrics <- get_exact_precision_recall_f1(egp_expected, wcx_predictions)

# This calculates the precision and recall for having predicted the exact level, or one level above or below.
neighbors_metrics <- get_neigh_prec_rec_f1(egp_expected, wcx_predictions)


print(exact_metrics)

print(neighbors_metrics)
```


Visualize how predictions relate to the EGP levels
```{r}
library(caret)


cm <- confusionMatrix(data = as.factor(wcx_predictions), reference = as.factor(egp_expected))["table"]

conf_matrix <- table("EGP" = egp_expected, "Predicted" = wcx_predictions)
cf <- as.data.frame(conf_matrix)


conf_matrix_heatmap <-  ggplot(data = as.data.frame(cf), aes(x = Predicted, y =  EGP, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), color = "black") +
  theme_light() +
  guides(scale = NULL) +
  coord_fixed() +
  scale_fill_gradient(low="white", high="#3c8b3c")
conf_matrix_heatmap
```

```{r}

```

```{r}

```


```{r}
```


```{r}
```